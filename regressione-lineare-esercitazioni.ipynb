{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Esercitazione 2 - Regressione Lineare**","metadata":{}},{"cell_type":"markdown","source":"## Boston Housing dataset","metadata":{}},{"cell_type":"markdown","source":"Questo dataset contiene informazioni raccolte dal U.S. Census Service riguardanti le abitazioni nell'area di Boston, Massachusetts. È stato ottenuto dall'archivio StatLib (http://lib.stat.cmu.edu/datasets/boston) ed è stato ampiamente utilizzato in letteratura per fare benchmark di algoritmi. \n\nIl dataset contiene informazioni su 506 case, divise in 14 variabili.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:53.482204Z","iopub.execute_input":"2025-04-04T17:00:53.482580Z","iopub.status.idle":"2025-04-04T17:00:53.487518Z","shell.execute_reply.started":"2025-04-04T17:00:53.482553Z","shell.execute_reply":"2025-04-04T17:00:53.485852Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd \nfrom sklearn.utils import shuffle\nfrom pandas import read_csv\n\nfrom sklearn.datasets import fetch_openml\nimport pandas as pd\n\n# Scarica il Boston Housing Dataset da OpenML\nboston = fetch_openml(name=\"Boston\", version=1, as_frame=True)\n\n# Estrai i dati (features) e il target (valore mediano delle abitazioni)\nX = boston.data\ny = boston.target\n\nX, y = shuffle(X, y, random_state=0)\nprint(f\"Features shape: {X.shape}, targets shape:  {y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:53.514928Z","iopub.execute_input":"2025-04-04T17:00:53.515319Z","iopub.status.idle":"2025-04-04T17:00:57.368379Z","shell.execute_reply.started":"2025-04-04T17:00:53.515286Z","shell.execute_reply":"2025-04-04T17:00:57.367294Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## `np.c_` in NumPy\n\nL'oggetto `np.c_` in NumPy è una **scorciatoia** per concatenare array lungo il secondo asse (cioè, le colonne).\n\n## Utilizzo\n```python\nnp.c_[array1, array2, ...]\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Generate two random 2x3 matrices\nmatrice1 = np.random.rand(2, 3)\nmatrice2 = np.random.rand(2, 3)\n\n# Concatenate the matrices along columns\nrisultato = np.c_[matrice1, matrice2]\n\nprint(\"Matrice 1:\",matrice1.shape)\n\nprint(\"\\nMatrice 2:\",matrice2.shape)\n\nprint(\"\\nMatrice concatenata:\",risultato.shape)","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:57.369877Z","iopub.execute_input":"2025-04-04T17:00:57.370579Z","iopub.status.idle":"2025-04-04T17:00:57.378516Z","shell.execute_reply.started":"2025-04-04T17:00:57.370545Z","shell.execute_reply":"2025-04-04T17:00:57.376705Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Divisione del dataset**\n\nIl primo passaggio è quello di dividere i dati in train set, validation set e test set. Utilizza il 60% dei dati per il training set, il 20% per il validation e il restante 20% per il test set. Considerato che il nostro dataset possiede 506 osservazioni mi aspetto che:\n\n- Il **training set** avrà 303 osservazioni.\n- Il **validation set** avrà 101 osservazioni.\n- Il **test set** avrà 101 osservazioni.\n\nIn reatà il test set avrà 102 osservazioni per via delle approssimazioni.\n\n","metadata":{}},{"cell_type":"code","source":"# Divisione del dataset\n\ntrain_porzione = 0.6  \nval_porzione = 0.2  \ntest_porzione = 0.2\n\n# svolgimento...\n\nnum_train = int(train_porzione * X.shape[0])   #x.shape[0] restituisce il numero di osservazioni nel dataset cioè 506\nnum_validation = int(val_porzione * X.shape[0])\n\n#CREAZIONE DEL TRAINING SET\nX_train = X[:num_train]  #prende le prime righe di X fino al valore num_train\ny_train = y[:num_train]  #prende le prime 303 righe di Y fino al valore num_train\n\n#CREAZIONE DEL VALIDATION TEST\nX_validation = X[num_train:num_train+num_validation]\ny_validation = y[num_train:num_train+num_validation]\n\n#CREAZIONE DEL TEST SET\nX_test = X[num_train+num_validation:]\ny_test = y[num_train+num_validation:]\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:57.381673Z","iopub.execute_input":"2025-04-04T17:00:57.382041Z","iopub.status.idle":"2025-04-04T17:00:57.408425Z","shell.execute_reply.started":"2025-04-04T17:00:57.382006Z","shell.execute_reply":"2025-04-04T17:00:57.407201Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Esercizio 1: Costruisci una Pipeline di Regressione Lineare Standardizzata**\n\n**Step 1:** Standardizza i dataset di addestramento, validazione e test. Usa `StandardScaler` di scikit-learn.  \n\n**Step 2:** Aggiungi una feature costante (bias) ai dati concatenando una colonna di uno ad ogni dataset.  \n\n**Step 3:** Implementa la soluzione in forma chiusa per l'addestramento di un modello di regressione lineare. \n \n**Step 4:** Valuta il modello calcolando il Mean Absolute Error (MAE) sui dataset di addestramento, validazione e test.\n","metadata":{}},{"cell_type":"markdown","source":"### **Guida**\n\n1. **StandardScaler**:\n   - Utilizza `StandardScaler` da `sklearn.preprocessing` per standardizzare i dati.\n   - Il metodo `fit_transform` calcola la media e la varianza dei dati di addestramento e li scala di conseguenza.\n   - Utilizza `transform` per standardizzare i dati di validazione e test utilizzando gli stessi parametri. Utilizziamo il metodo `transform` perchè non calcola i parametri di scaling (media e std). In questo modo ci assicuriamo che i dati di training e quelli di validation e test vengano scalati in modo uguale. Se usassimo `fit_transform` avremmo degli scaling diversi.\n\n2. **Aggiunta di una Caratteristica Costante**:\n   - Utilizza `np.c_` per concatenare una colonna di uno alle matrici delle caratteristiche. Questo è importante per includere il termine di intercetta nella regressione lineare.\n\n3. **Soluzione in Forma Chiusa per la Regressione Lineare**:\n   - La soluzione in forma chiusa è:\n\n     $$\\theta = (X^T X)^{-1} X^T y$$\n\n   - Per calcolare la trasposta di una matrice possiamo utilizzare l' attributo `.T` di cui ogni array è dotato.\n\n   - Utilizza `np.linalg.inv` di NumPy per l'inversione della matrice e l'operatore `@` per la moltiplicazione matriciale.\n  \n   - Puoi utilizzare l'operatore @ per eseguire l'operazione np.dot (`A @ B` è equivalente a `np.dot(A, B)`).\n\n4. **Mean Absolute Error (MAE)**:\n   - L'MAE si calcola come:\n\n     $$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|$$\n\n   - Utilizza `np.mean` e `np.abs` per calcolarlo.\n","metadata":{}},{"cell_type":"code","source":"# Step 1 - Normalizzazione dei dati. Dobbiamo normalizzare le features \n# sia del training set, validation set e test set.\n\n# Utilizziamo il metodo .fit_transform() dello scaler per normalizzare le feature di training.\n\n# Per normalizzare le feature di validation e test utilizziamo il metodo .transform()\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)          #calcola la media e la deviazione standard su X_train e applica la trasformazione\n\nX_validation = scaler.transform(X_validation)    #qui si applica .transform() perchè dobbiamo usare la stessa trasformazione calcolata sui dati di training. cioè riutilizzare la stessa media e deviazione standard caclolata prima   \nX_test = scaler.transform(X_test)                    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:57.410484Z","iopub.execute_input":"2025-04-04T17:00:57.411074Z","iopub.status.idle":"2025-04-04T17:00:57.457163Z","shell.execute_reply.started":"2025-04-04T17:00:57.411030Z","shell.execute_reply":"2025-04-04T17:00:57.455672Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Aggiunta di una feature costante\n\n# creiamo un vettore di 1 da aggiungere come feature costante. \n# ATTENZIONE: questo vettore deve avere le stesse righe del set a cui viene aggiunto. \n# Uno uguale per tutti non va bene\n\n# svolgimento...\nX_train = np.c_[np.ones((X_train.shape[0], 1)), X_train]\nX_validation = np.c_[np.ones((X_validation.shape[0], 1)), X_validation]\nX_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:03:35.535959Z","iopub.execute_input":"2025-04-04T17:03:35.536372Z","iopub.status.idle":"2025-04-04T17:03:35.542241Z","shell.execute_reply.started":"2025-04-04T17:03:35.536343Z","shell.execute_reply":"2025-04-04T17:03:35.541002Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Applichiamo la formula matematica della regressione lineare\n\n# ATTENZIONE: stiamo per effettuare operazioni tra matrici e vettori, \n# non si tratta di una semplice formula matematica, stiamo attenti a quali operatori utilizzare e quanto\n\n# svolgimento...\n\nparametri = np.linalg.pinv(X_train.T @ X_train) @ X_train.T @ y_train\n\ny_train_predizioni = X_train @ parametri \ny_val_predizioni = X_validation @ parametri\ny_test_predizioni = X_test @ parametri\n\nprint(y_train_predizioni.shape)\nprint(y_val_predizioni.shape)\nprint(y_test_predizioni.shape)","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:22:53.758497Z","iopub.execute_input":"2025-04-04T17:22:53.758873Z","iopub.status.idle":"2025-04-04T17:22:53.766659Z","shell.execute_reply.started":"2025-04-04T17:22:53.758843Z","shell.execute_reply":"2025-04-04T17:22:53.765275Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Calcolo MAE\n\n# Calcoliamo l'errore medio assoluto (MAE) per il training set, validation set e test set.\n# Utlizziamo la formula specificata nella guida.\n\n# svolgimento...\n\nmae_train = np.mean(np.abs(y_train - y_train_predizioni))\nmae_val = np.mean(np.abs(y_validation - y_val_predizioni))\nmae_test = np.mean(np.abs(y_test - y_test_predizioni))\n\nprint(f\"MAE Train: {mae_train}\")\nprint(f\"MAE Validation: {mae_val}\")\nprint(f\"MAE Test: {mae_test}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:33:34.837963Z","iopub.execute_input":"2025-04-04T17:33:34.838344Z","iopub.status.idle":"2025-04-04T17:33:34.846357Z","shell.execute_reply.started":"2025-04-04T17:33:34.838306Z","shell.execute_reply":"2025-04-04T17:33:34.845036Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Esercizio: Costruisci una pipeline di Regressione Lineare Standardizzata utilizzando `scikit-learn`** \n\n**Step 1 & 2:** Step 1 e 2 sono uguali a quanto fatto prima.\n\n**Step 3:** Utilizza `LinearRegression()` di scikit-learn per addestrare un modello di regressione lineare.  \n\n**Step 4:** Valuta il modello calcolando il Mean Absolute Error (MAE) sui dataset di addestramento, validazione e test, utilizzando `mean_absolute_error()` da `sklearn.metrics`.\n","metadata":{}},{"cell_type":"markdown","source":"## `LinearRegression` da Scikit-Learn\n\nLa classe `LinearRegression` in Scikit-Learn viene utilizzata per eseguire la **regressione lineare**, adattando un modello lineare al dataset.\n\n## **Sintassi**\n```python\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\n# Dati di esempio\nX = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\ny = np.array([10, 15, 20, 25])\n\n# Adatta il modello ai dati\nmodel.fit(X, y)\n\n# Predici nuovi valori\nX_new = np.array([[3, 5], [5, 9]])\npredictions = model.predict(X_new)\n","metadata":{}},{"cell_type":"markdown","source":"## `mean_absolute_error` da Scikit-Learn\n\nLa funzione `mean_absolute_error` calcola l'**errore assoluto medio** (MAE) tra i valori target reali e quelli predetti.\n\n## **Sintassi**\n```python\nsklearn.metrics.mean_absolute_error(y_true, y_pred)\n","metadata":{}},{"cell_type":"markdown","source":"### **Guida**\n\n1. **Istanziare e allenare un modello di regressione lineare**:\n    \n    - Istanziamo una classe `LinearRegression` per creare il modello.\n    - Utilizziamo il metodo `.fit()` per allenare il modello con i dati di training.\n\n2. **Effettuare predizioni con il modello**:\n\n    - Utiliziamo il metodo `.predict()` del modello per effettuare le predizioni. Effettuiamo le predizioni per tutti i set che abbiamo (train, validation e test).\n\n3. **Calcolo della MAE**: \n\n    - Calcolare MAE su tutti i set utilizzando la funzione `mean_abslute_error`\n","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:48:34.416393Z","iopub.execute_input":"2025-04-04T17:48:34.416780Z","iopub.status.idle":"2025-04-04T17:48:34.671021Z","shell.execute_reply.started":"2025-04-04T17:48:34.416753Z","shell.execute_reply":"2025-04-04T17:48:34.669612Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1 - Istanziare e allenare il modello di regressione lineare.\n\n# svolgimento...\nmodel = LinearRegression()\n\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2025-04-04T18:05:14.810273Z","iopub.execute_input":"2025-04-04T18:05:14.810746Z","iopub.status.idle":"2025-04-04T18:05:14.829999Z","shell.execute_reply.started":"2025-04-04T18:05:14.810715Z","shell.execute_reply":"2025-04-04T18:05:14.828868Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Effettuare predizioni\n\n# svolgimento...\n\ny_train_pred = model.predict(X_train)\ny_val_pred = model.predict(X_validation)\ny_test_pred = model.predict(X_test)\n\nprint (y_train_pred.shape)\nprint (y_val_pred.shape) \nprint (y_test_pred.shape)","metadata":{"execution":{"iopub.status.busy":"2025-04-04T18:09:33.192442Z","iopub.execute_input":"2025-04-04T18:09:33.192832Z","iopub.status.idle":"2025-04-04T18:09:33.201419Z","shell.execute_reply.started":"2025-04-04T18:09:33.192805Z","shell.execute_reply":"2025-04-04T18:09:33.199648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Calcolo MAE\n\n\nmae_train = mean_absolute_error(y_train, y_train_pred)\nmae_val = mean_absolute_error(y_validation, y_val_pred)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(f\"MAE Training Set: {mae_train:.4f}\")\nprint(f\"MAE Validation Set: {mae_val:.4f}\")\nprint(f\"MAE Test Set: {mae_test:.4f}\")\n\n# svolgimento...","metadata":{"execution":{"iopub.status.busy":"2025-04-04T18:17:51.855424Z","iopub.execute_input":"2025-04-04T18:17:51.855962Z","iopub.status.idle":"2025-04-04T18:17:51.865936Z","shell.execute_reply.started":"2025-04-04T18:17:51.855928Z","shell.execute_reply":"2025-04-04T18:17:51.864758Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Esercizio: Crea una funzione che esegua una pipeline di Regressione Lineare**\n\nLa funzione deve richiedere un parametro `hyperparams` per gestire i diversi casi. \n\n`hyperparams` deve essere un dizionario contenente diverse chiavi, in base al valore di queste chiavi devono essere eseguiti (oppure no) diversi pezzi di codice. \n\nIn questo esercizio la chiave da utilizzare sarà `hyperparams['data_standardize']`. Se il valore di questa chiave sarà **True** allora eseguire la standardizzazione con `scikit-learn`, se invece è **False** non verrà eseguita alcuna standardizzazione.\n\n**Step 1:** Controllare se eseguire o no la standardizzazione.\n\n* **Step 1.1:** Scrivere il codice per eseguire la standardizzazione.\n\n**Step 2:** Utilizza `np.c_` per concatenare una colonna di uno alle matrici delle caratteristiche.\n\n**Step 3:** Applichiamo la formula matematica della regressione lineare.\n\n**Step 4:** Calcolo MAE utilizzando la formula (NON con `scikit-learn`).\n\nLa funzione deve ritornare i valori della MAE.","metadata":{}},{"cell_type":"markdown","source":"Dopo aver testato i risultati con `hyperparams['data_standardize']` = **True**, provare anche i risultati ottenuti se `hyperparams['data_standardize']` = **False**.","metadata":{}},{"cell_type":"code","source":"# svolgimento...\n\ndef pipeline(X_train, y_train, X_val, y_val, hyperparams):\n\n    X_train = np.array(X_train, dtype=float)\n    y_train = np.array(y_train, dtype=float)\n    X_val = np.array(X_val, dtype=float)\n    y_val = np.array(y_val, dtype=float)\n    \n    # Step 1 - Controllo se è richiesta la standardizzazione dei dati\n    if hyperparams['data_standardize']:\n        \n        # Step 1.1 - Scrivere il codice per standardizzare i dati \n\n    \n    # Step 2 - Concatenare una colonna di uno alla matrice delle features\n\n    # Step 3 - Applicare formula della regressione lineare e calcolare predizioni\n\n    # Step 4 - Calcolare MAE ","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:57.485849Z","iopub.status.idle":"2025-04-04T17:00:57.486259Z","shell.execute_reply":"2025-04-04T17:00:57.486075Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hyperparams = {'data_standardize': True}\n\ntrain_fraction = 0.8\nvalidation_fraction = 0.2\n\nnum_train = int(train_fraction * X.shape[0])\n\nX_train = X[:num_train]\ny_train = y[:num_train]\n\nX_validation = X[num_train:]\ny_validation = y[num_train:]\n\n# Chiamare la funzione pipeline e stampare i risultati della MAE\n\n# svolgimento...","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:57.487133Z","iopub.status.idle":"2025-04-04T17:00:57.487550Z","shell.execute_reply":"2025-04-04T17:00:57.487353Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Esercizio: Implementare alla funzione `pipeline` la possibilità di usare PCA**\n\nModifichiamo la funzione `pipeline` in modo da gestire anche la possibilità di effettuare la PCA. Dunque aggiungiamo al dizionario `hyperparams` la chiave `use_pca`. \n\nSe `hyperparams['use_pca']` = **True** verrà eseguita la PCA. \n\nSe `hyperparams['use_pca']` = **False** non verrà eseguita la PCA.\n\nLa gestione della standardizzazione deve essere mantenuta come prima.","metadata":{}},{"cell_type":"code","source":"# svolgimento...\nfrom sklearn.decomposition import PCA\n\ndef pipeline(X_train, y_train, X_val, y_val, hyperparams):\n\n    X_train = np.array(X_train, dtype=float)\n    y_train = np.array(y_train, dtype=float)\n    X_val = np.array(X_val, dtype=float)\n    y_val = np.array(y_val, dtype=float)\n\n    # Step 1 - Controllo se è richista la PCA\n    if hyperparams['use_pca']:\n        \n        # Step 1.1 - Scrivere il codice per applicare PCA\n    \n    # Step 2 - Controllo se è richiesta la standardizzazione dei dati\n    if hyperparams['data_standardize']:\n        \n        # Step 2.1 - Scrivere il codice per standardizzare i dati \n\n\n    # Step 3 - Concatenare una colonna di uno alla matrice delle features\n\n    # Step 4 - Applicare formula della regressione lineare e calcolare predizioni\n\n    # Step 5 - Calcolare MAE ","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:57.488382Z","iopub.status.idle":"2025-04-04T17:00:57.488822Z","shell.execute_reply":"2025-04-04T17:00:57.488649Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hyperparams = {'data_standardize': True, 'use_pca': True}\ntrain_fraction = 0.8\nvalidation_fraction = 0.2\n\nnum_train = int(train_fraction * X.shape[0])\n\nX_train = X[:num_train]\ny_train = y[:num_train]\n\nX_validation = X[num_train:]\ny_validation = y[num_train:]\n\n# Chiamare la funzione pipeline e stampare i risultati della MAE al variare dell' utilizzo della PCA.\n\n# svolgimento...","metadata":{"execution":{"iopub.status.busy":"2025-04-04T17:00:57.490512Z","iopub.status.idle":"2025-04-04T17:00:57.491179Z","shell.execute_reply":"2025-04-04T17:00:57.490826Z"},"trusted":true},"outputs":[],"execution_count":null}]}